{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fsWUTn_dyL31"
   },
   "outputs": [],
   "source": [
    "# !pip install google-cloud-speech\n",
    "# !pip install google-cloud-storage\n",
    "# !pip install pydub\n",
    "# !pip install speechbrain\n",
    "# !pip install torchvision==0.12.0 torchtext==0.12.0 torchaudio==0.11.0\n",
    "# !pip install pyannote.audio\n",
    "# !pip install pyannote.core\n",
    "# !pip install underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HYukI4msyL36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Phat Dat/.cache\\torch\\hub\\pyannote_pyannote-audio_master\n",
      "Using cache found in C:\\Users\\Phat Dat/.cache\\torch\\hub\\pyannote_pyannote-audio_master\n",
      "Using cache found in C:\\Users\\Phat Dat/.cache\\torch\\hub\\pyannote_pyannote-audio_master\n",
      "Using cache found in C:\\Users\\Phat Dat/.cache\\torch\\hub\\pyannote_pyannote-audio_master\n",
      "c:\\Users\\Phat Dat\\anaconda3\\envs\\s2t_GCP_Final\\lib\\site-packages\\pyannote\\audio\\embedding\\approaches\\arcface_loss.py:170: FutureWarning: The 's' parameter is deprecated in favor of 'scale', and will be removed in a future release\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "c:\\Users\\Phat Dat\\anaconda3\\envs\\s2t_GCP_Final\\lib\\site-packages\\pyannote\\audio\\features\\pretrained.py:156: UserWarning: Model was trained with 4s chunks and is applied on 2s chunks. This might lead to sub-optimal results.\n",
      "  warnings.warn(msg)\n",
      "Using cache found in C:\\Users\\Phat Dat/.cache\\torch\\hub\\pyannote_pyannote-audio_master\n"
     ]
    }
   ],
   "source": [
    "## Library\n",
    "import os\n",
    "from pydub import AudioSegment, silence\n",
    "import wave\n",
    "from google.cloud import speech\n",
    "from google.cloud import storage\n",
    "import torch\n",
    "import io\n",
    "\n",
    "pipeline = torch.hub.load('pyannote/pyannote-audio', 'dia')\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'Speech2Text.json'\n",
    "\n",
    "## Tạo thư mục cho từng tác vụ\n",
    "Thu_muc_cho_audio_cat_theo_giong_noi = 'Splited_speaker'\n",
    "Thu_muc_cho_audio_cat_theo_silence   = 'Splited_Silence'\n",
    "\n",
    "os.makedirs(Thu_muc_cho_audio_cat_theo_giong_noi ,exist_ok= True)\n",
    "os.makedirs(Thu_muc_cho_audio_cat_theo_silence   ,exist_ok= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PmhAg0RZyL37"
   },
   "outputs": [],
   "source": [
    "# Split Speaker\n",
    "def Split_speaker(audio_file):\n",
    "    Audio = AudioSegment.from_file(audio_file)\n",
    "    name = Thu_muc_cho_audio_cat_theo_giong_noi + '/' + audio_file.split('/')[-1].replace('.wav', '')\n",
    "\n",
    "    os.makedirs(name, exist_ok=True)\n",
    "    hashDict = dict()\n",
    "    diarization = pipeline({'audio':audio_file})\n",
    "    \n",
    "    i,start,end,lab = 0,0,0,0\n",
    "    for segment,track,label in diarization.itertracks(yield_label = True):\n",
    "        if label != lab:\n",
    "            Audio_speaker_i = Audio[start * 1000 : end * 1000]\n",
    "            Audio_speaker_i.export(name + '/' + str(i) + '.wav', format = 'wav')\n",
    "            hashDict[name + '/' +str(i) + '.wav'] = lab\n",
    "            i += 1\n",
    "            start = segment.start\n",
    "            end = segment.end\n",
    "            lab = label\n",
    "        elif label == lab:\n",
    "            end = segment.end\n",
    "    # chạy vòng cuối\n",
    "    Audio_speaker_i = Audio[start * 1000 : end * 1000]\n",
    "    Audio_speaker_i.export(name +'/' + str(i) + '.wav', format = 'wav')\n",
    "    hashDict[name + '/' +str(i) + '.wav'] = lab\n",
    "    \n",
    "    os.remove(name + '/' + str(0) + '.wav')\n",
    "    hashDict.pop(name + '/' +str(0) + '.wav')\n",
    "    return hashDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6b-cBAiQyL38"
   },
   "outputs": [],
   "source": [
    "# Split Silence\n",
    "def export_audio(audio, count,name):\n",
    "    audios = audio.set_frame_rate(16000)\n",
    "    audios.export(os.path.join(name + '/file_{}.wav'.format(str(count))), format='wav')\n",
    "\n",
    "# hashDict: {speaker: (start, stop)}\n",
    "def split_silence(audio, speaker):\n",
    "    folder = Thu_muc_cho_audio_cat_theo_silence\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    name = audio.split('/')\n",
    "    name = name[-2] + \"/\" + name[-1].replace('.wav','')\n",
    "    name = os.path.join(folder,name)\n",
    "    os.makedirs(name, exist_ok=True)\n",
    "\n",
    "    myaudio = AudioSegment.from_file(audio, \"wav\")\n",
    "    dbfs = myaudio.dBFS\n",
    "    duration_in_sec = len(myaudio) / 1000\n",
    "\n",
    "    mydict = dict()\n",
    "    t_dict = dict()\n",
    "\n",
    "    # Lấy các khoảng silence trong audio\n",
    "    silences = silence.detect_silence(myaudio,\n",
    "                                      min_silence_len= 300,\n",
    "                                      silence_thresh=dbfs-10)\n",
    "    silences = [((start/1000),(stop/1000)) for start,stop in silences]\n",
    "    # print(silences)\n",
    "\n",
    "    if len(silences) > 0:\n",
    "        n_silence = []\n",
    "        if silences[0][0] == 0.0:\n",
    "            n_silence.append(silences[0])\n",
    "            silences.pop(0)\n",
    "\n",
    "        # Chỉnh lại, làm tròn sec\n",
    "        for i in silences:\n",
    "            if round(i[0]) < i[0]:\n",
    "                temp= (i[0]+0.5, i[1])\n",
    "            else:\n",
    "                temp= (round(i[0]), i[1])\n",
    "            n_silence.append(temp)\n",
    "        \n",
    "\n",
    "        count = 1\n",
    "        for start,end in silences:\n",
    "            temp= name+'/file_'+str(count)+'.wav' # vị trí file: lưu file ở thư mục nào thì địa chỉ tới thư mục đó\n",
    "            t_dict[temp]= end-start\n",
    "            count +=1\n",
    "        \n",
    "\n",
    "        start = 0.0\n",
    "        end = duration_in_sec\n",
    "        s_audio = myaudio[start*1000:n_silence[0][0]*1000]\n",
    "        export_audio(s_audio, 1,name)\n",
    "        count = 2\n",
    "        for i in range(len(n_silence)-1):\n",
    "            s= n_silence[i][1]\n",
    "            e= n_silence[i+1][0]\n",
    "            n_audio = myaudio[s*1000:e*1000]\n",
    "            export_audio(n_audio, count,name)\n",
    "            count += 1\n",
    "        if n_silence[len(n_silence)-1][1] != end:\n",
    "            e_audio = myaudio[n_silence[len(n_silence)-1][1]*1000:end*1000]\n",
    "            export_audio(e_audio, count,name)\n",
    "            temp= name + '/file_'+str(count)+'.wav'\n",
    "            t_dict[temp] = 0\n",
    "    else:\n",
    "        temp= name+'/file_'+str(0)+'.wav'\n",
    "        export_audio(myaudio, 0,name)\n",
    "        t_dict[temp] = 0\n",
    "    mydict[speaker] = t_dict\n",
    "    return mydict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FiksNyA2yL39"
   },
   "outputs": [],
   "source": [
    "# tổng hợp bucket hiện có\n",
    "def list_buckets():\n",
    "    \"\"\"Lists all buckets.\"\"\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    buckets = storage_client.list_buckets()\n",
    "\n",
    "    for bucket in buckets:\n",
    "        print(bucket.name)\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\n",
    "        f\"File {source_file_name} uploaded to {destination_blob_name}.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nrEwv_ewyL39"
   },
   "outputs": [],
   "source": [
    "# Một số Function hỗ trợ xử lý văn bản đầu ra\n",
    "def is_digit(word):\n",
    "    try:\n",
    "        int(word)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "\n",
    "def ConvertDate(text):\n",
    "    month=' tháng '\n",
    "    year=' năm '\n",
    "    for index in range(0,len(text)):\n",
    "        try:\n",
    "            if (text.index(month,index)==index):\n",
    "                dateNum = text[index -1]\n",
    "                monthNum = text[index + len(month)]\n",
    "                if is_digit(dateNum) and is_digit(monthNum):\n",
    "                    text=text[:index] + text[index+len(month)-1:]\n",
    "                    temp = list(text)\n",
    "                    temp[index]='/'\n",
    "                    text = \"\".join(temp)\n",
    "        except Exception as e:\n",
    "            if str(e) in 'substring not found':\n",
    "                pass\n",
    "            else:\n",
    "                raise e\n",
    "        try:\n",
    "            if (text.index(year,index)==index):\n",
    "                monthNum = text[index -1]\n",
    "                yearNum = text[index + len(year)]\n",
    "                if is_digit(monthNum) and is_digit(yearNum):\n",
    "                    text=text[:index] + text[index+len(year)-1:]\n",
    "                    temp = list(text)\n",
    "                    temp[index]='/'\n",
    "                    text = \"\".join(temp)\n",
    "        except Exception as e:\n",
    "            if str(e) in 'substring not found':\n",
    "                pass\n",
    "            else:\n",
    "                raise e\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AiwKRSbpyL3-"
   },
   "outputs": [],
   "source": [
    "# Các Function xử dụng GCP API thực hiện speech to text\n",
    "def frame_rate_channel(audio_file_name):\n",
    "    print(audio_file_name)\n",
    "    with wave.open(audio_file_name, \"rb\") as wave_file:\n",
    "        frame_rate = wave_file.getframerate()\n",
    "        channels = wave_file.getnchannels()\n",
    "        return frame_rate,channels\n",
    "\n",
    "## Config_GGC_model_before_Transcribe\n",
    "def Config_GGC(sample_rate_hertz = 44100,\n",
    "                audio_channel_count = 1,\n",
    "                model = None,\n",
    "                enable_automatic_punctuation=True):\n",
    "    if model != None:\n",
    "        config_wav_enhanced = speech.RecognitionConfig(\n",
    "            sample_rate_hertz = sample_rate_hertz,\n",
    "            enable_automatic_punctuation=enable_automatic_punctuation,\n",
    "            language_code = 'vi-VN',\n",
    "            audio_channel_count=audio_channel_count,\n",
    "            model = model,\n",
    "        )\n",
    "    else :\n",
    "        config_wav_enhanced = speech.RecognitionConfig(\n",
    "            sample_rate_hertz = sample_rate_hertz,\n",
    "            enable_automatic_punctuation=True,\n",
    "            language_code = 'vi-VN',\n",
    "            audio_channel_count=audio_channel_count\n",
    "        )\n",
    "    return config_wav_enhanced\n",
    "## Config_GGC that doesn't have punctuation\n",
    "def Config_noPunc(sample_rate_hertz = 44100,\n",
    "                audio_channel_count = 1,\n",
    "                model = None,\n",
    "                enable_automatic_punctuation=True):\n",
    "    if model is not None:\n",
    "        config_wav_enhanced = speech.RecognitionConfig(\n",
    "            sample_rate_hertz = sample_rate_hertz,\n",
    "            language_code = 'vi-VN',\n",
    "            audio_channel_count=audio_channel_count,\n",
    "            model = model,\n",
    "        )\n",
    "    else :\n",
    "        config_wav_enhanced = speech.RecognitionConfig(\n",
    "            sample_rate_hertz = sample_rate_hertz,\n",
    "            language_code = 'vi-VN',\n",
    "            audio_channel_count=audio_channel_count\n",
    "        )\n",
    "    return config_wav_enhanced\n",
    "\n",
    "def Transcribe_Short_Audio(Audio_wav,config_wav_enhanced):\n",
    "    client = speech.SpeechClient()\n",
    "    with io.open(Audio_wav, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "    # print(type(audio))\n",
    "    \n",
    "    response = client.recognize(config=config_wav_enhanced, audio=audio)\n",
    "    text = []\n",
    "    for i, result in enumerate(response.results):\n",
    "        alternative = result.alternatives[0]\n",
    "        alter=ConvertDate(alternative.transcript+ '\\n')\n",
    "        text.append(alter)\n",
    "    return text\n",
    "\n",
    "### This function is main on stranscribe\n",
    "def Transcribe_Long_Audio(Audio_wav,config_wav_enhanced,\n",
    "                        bucket_name = 'speech_to_text_stech',\n",
    "                        Name = 'Audio_wav'):\n",
    "    client = speech.SpeechClient()\n",
    "    Audio_name = Audio_wav.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    upload_blob(bucket_name,Audio_wav,Name)\n",
    "    \n",
    "    media_uri = \"gs://{}/{}\".format(bucket_name,Name)\n",
    "    long_audi_wav = speech.RecognitionAudio(uri=media_uri)\n",
    "    \n",
    "    \n",
    "    operations = client.long_running_recognize(\n",
    "        config = config_wav_enhanced,\n",
    "        audio = long_audi_wav\n",
    "    )\n",
    "    \n",
    "    response = operations.result(timeout=90)\n",
    "\n",
    "    text = []\n",
    "    \n",
    "    for i, result in enumerate(response.results):\n",
    "            alternative = result.alternatives[0]\n",
    "            alter=ConvertDate(alternative.transcript)\n",
    "            text.append(alter)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9zZP7a_eyL3-"
   },
   "outputs": [],
   "source": [
    "##Take audio to text+punc\n",
    "def AudioToText(path,config):\n",
    "    try:\n",
    "        text=Transcribe_Short_Audio(path,config)\n",
    "    except:\n",
    "        text = Transcribe_Long_Audio(path,config)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ufASVnTSyL3_"
   },
   "outputs": [],
   "source": [
    "# Sử dụng Google API để dịch từng Audio sang text\n",
    "def GCP_s2t(alist):\n",
    "    index=list(alist[0])[0]\n",
    "    sample_file_config=list(alist[0][index])[0]\n",
    "    \n",
    "    rate,channel=frame_rate_channel(sample_file_config)\n",
    "    config = Config_GGC(sample_rate_hertz = rate,\n",
    "                 audio_channel_count = channel)\n",
    "    \n",
    "    config_noPunc = Config_GGC(sample_rate_hertz = rate,\n",
    "                 audio_channel_count = channel)\n",
    "\n",
    "    result_dict = {'Speaker':[], 'co dau':[],'khong dau':[],'silence':[]}\n",
    "    for adict in alist:\n",
    "        for speaker,value in adict.items():\n",
    "            for file_addr,silent_time in adict[speaker].items():\n",
    "                \n",
    "                #### Punc\n",
    "                text=AudioToText(file_addr,config)\n",
    "                #### No Punc\n",
    "                text_noPunc=AudioToText(file_addr,config_noPunc)\n",
    "                result_dict['Speaker'].append(speaker)\n",
    "                result_dict['co dau'].append(text)\n",
    "                result_dict['khong dau'].append(text_noPunc)\n",
    "                result_dict['silence'].append(silent_time)\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wcUMTlFTyL4A"
   },
   "outputs": [],
   "source": [
    "# Function Kết hợp Text có dấu theo Google API và silence\n",
    "\n",
    "def Handle_Text_Dict(adict,S_Punc_ok=False):\n",
    "    adict = list(adict.values())\n",
    "    Spr,SL = 0,0\n",
    "    ReDict = {'Speaker':[], 'co dau':[],'khong dau':[]}\n",
    "    Silent_Punc = []\n",
    "    for Speaker,Punc,NoPunc,Silent in zip(*adict):\n",
    "        # Vì Punc,NoPunc là list\n",
    "        new_Punc = str()\n",
    "        for i in Punc:\n",
    "            new_Punc += i\n",
    "        new_NoPunc = str()\n",
    "        for i in NoPunc:\n",
    "            new_NoPunc += i\n",
    "        \n",
    "        if Speaker != Spr:\n",
    "            # Làm gì đó\n",
    "            Spr = Speaker\n",
    "            SL = Silent\n",
    "            ReDict['Speaker'].append(Speaker)\n",
    "            \n",
    "            ReDict['khong dau'].append(new_NoPunc)\n",
    "            if S_Punc_ok == True:\n",
    "                ReDict['co dau'].append(new_NoPunc + '. ')\n",
    "            else:\n",
    "                ReDict['co dau'].append(new_Punc)\n",
    "        else: \n",
    "            ReDict['khong dau'][-1] += ' ' + new_NoPunc\n",
    "            ReDict['co dau'][-1] += ' ' + new_Punc\n",
    "    return ReDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4UZVzGHzyL4A"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Phat Dat\\anaconda3\\envs\\s2t_GCP_Final\\lib\\site-packages\\pyannote\\audio\\features\\utils.py:179: FutureWarning: Pass orig_sr=48000, target_sr=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  y = librosa.core.resample(y[:, 0], sample_rate, self.sample_rate)[:, None]\n",
      "c:\\Users\\Phat Dat\\anaconda3\\envs\\s2t_GCP_Final\\lib\\site-packages\\pyannote\\audio\\features\\utils.py:179: FutureWarning: Pass orig_sr=48000, target_sr=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  y = librosa.core.resample(y[:, 0], sample_rate, self.sample_rate)[:, None]\n"
     ]
    }
   ],
   "source": [
    "# Phần ghép các Function\n",
    "Audio_Input = 'Input/23-06-2022 14 12 36.wav'\n",
    "\n",
    "# Đưa các lệnh dưới đây của cell này vô Function là ta có Pipeline\n",
    "\n",
    "# splited speaker\n",
    "hashDict = Split_speaker(Audio_Input)\n",
    "\n",
    "# splited Silence\n",
    "My_info = []\n",
    "for audio,speaker in hashDict.items():\n",
    "    my_dict = split_silence(audio,speaker)\n",
    "    My_info.append(my_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "RlKL6PEYyL4B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splited_Silence\\23-06-2022 14 12 36/1/file_0.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/1/file_0.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/2/file_1.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/2/file_1.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/2/file_2.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/2/file_2.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/2/file_3.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/2/file_3.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/2/file_4.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/2/file_4.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/2/file_5.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/2/file_5.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/2/file_6.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/2/file_6.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/2/file_7.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/2/file_7.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/3/file_0.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/3/file_0.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/4/file_1.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/4/file_1.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/4/file_2.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/4/file_2.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/4/file_3.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/4/file_3.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/4/file_4.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/4/file_4.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/4/file_5.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/4/file_5.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/4/file_6.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/4/file_6.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_1.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_1.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_2.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_2.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_3.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_3.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_4.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_4.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_5.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_5.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_6.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_6.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_7.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_7.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_8.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_8.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_9.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_9.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_10.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_10.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_11.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_11.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_12.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_12.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_13.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_13.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_14.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_14.wav\n",
      "chanel:  2\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_15.wav\n",
      "Splited_Silence\\23-06-2022 14 12 36/5/file_15.wav\n",
      "chanel:  2\n"
     ]
    }
   ],
   "source": [
    "# Chuyển từng audio thành text có dấu và không dấu\n",
    "Text_Dict=GCP_s2t(My_info)\n",
    "\n",
    "# Chuyển thành Dict theo yêu cầu của Tín và để cho phần tìm silent\n",
    "Result = Handle_Text_Dict(Text_Dict)\n",
    "Result2 = Handle_Text_Dict(Text_Dict,S_Punc_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uepNC-ZfyL4D",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from underthesea import pos_tag as pot\n",
    "import re\n",
    "\n",
    "def add_punc(final, final_with_punc):\n",
    "    x = final\n",
    "    y = final_with_punc\n",
    "    new = []\n",
    "    for i in range(len(x)):\n",
    "        if ':' in x[i]:\n",
    "            t = x[i].split(':')[1].strip()\n",
    "            new.append(x[i].replace(t, y[i]))\n",
    "        else:\n",
    "            new.append(y[i])\n",
    "    return new\n",
    "\n",
    "\n",
    "def recognize(conser):\n",
    "\n",
    "    def capital(noun):\n",
    "        return ' '.join([str(wordx).capitalize() for wordx in noun.split()])\n",
    "\n",
    "    final = conser\n",
    "    military_rank = ['đại tướng', 'trung tướng', 'thiếu tướng', 'đại tá','thượng tá', 'trung tá', 'thiếu tá', 'đại úy', 'thượng úy', 'trung úy', 'thiếu úy']\n",
    "    start_para = [ 'xin trân trọng kính','tôi xin kính','xin kính','tôi xin', 'xin', 'kính','tôi']\n",
    "    vocative = ['đồng chí', 'đại biểu']\n",
    "    checkpoint_start = ['phát biểu','đặt câu hỏi','trả lời','cho ý kiến','nêu ý kiến']\n",
    "    end_para = ['tôi xin báo cáo hết', 'xin phép báo cáo hết' ,'xin báo cáo hết'\n",
    "               , 'xin phép hết','báo cáo hết','tôi xin hết', 'xin hết']\n",
    "    thank_full = ['tôi xin cảm ơn','tôi cảm ơn','cảm ơn']\n",
    "    end_co=[]\n",
    "    for i in end_para:\n",
    "        for j in thank_full:\n",
    "            end = i+' '+j\n",
    "            end_co.append(end)\n",
    "\n",
    "    pos = pot(final)\n",
    "    #nhận diện chỉ tử mời\n",
    "    for i, (wor, tag) in enumerate(pos):\n",
    "        if wor == 'mời' and i != len(pos)-1 and i != 0:\n",
    "            if pos[i+1][0] in vocative and str(pos[i-1][0]).lower() not in start_para:\n",
    "                original = pos[i-1][0] + ' mời'\n",
    "                subtitute = pos[i-1][0] + ' xin mời'\n",
    "                final = final.replace( original, subtitute)\n",
    "            elif pos[i+1][0] in military_rank and str(pos[i-1][0]).lower() not in start_para:\n",
    "                original = pos[i-1][0] + ' mời ' + pos[i+1][0]\n",
    "                subtitute = pos[i-1][0] + ' xin mời đồng chí'\n",
    "                final = final.replace(original, subtitute)\n",
    "    words = []\n",
    "    tags = []\n",
    "    # Thay thế tất cả start bằng xin_mời\n",
    "    for start in start_para:\n",
    "        find = re.compile(start+' mời')\n",
    "        for m in find.finditer(final.lower()):\n",
    "            sta_in , end_in = m.start(), m.end()\n",
    "            final = final[0:sta_in] + 'xin_mời' + final[end_in:]\n",
    "    #Thay thế các end_co bằng báo cáo hết\n",
    "    for end in end_co:\n",
    "        find = re.compile(end)\n",
    "        for m in find.finditer(final.lower()):\n",
    "            sta_in, end_in = m.start(), m.end()\n",
    "            final = final[0:sta_in] + 'báo_cáo_hết' + final[end_in:]\n",
    "    #Thay thế tất cả end bằng báo_cáo_hết\n",
    "    for end in end_para:\n",
    "        find = re.compile(end)\n",
    "        for m in find.finditer(final.lower()):\n",
    "            sta_in, end_in = m.start(), m.end()\n",
    "            final = final[0:sta_in] + 'báo_cáo_hết' + final[end_in:]\n",
    "\n",
    "\n",
    "    # Lưu từ và phân loại vào list words, tags\n",
    "    postag = pot(final)\n",
    "    for text, tag in postag:\n",
    "        words.append(text)\n",
    "        tags.append(tag)\n",
    "    # Xử lý văn bản\n",
    "    for i, word in enumerate(words):\n",
    "        # Xét trường hợp không phải những từ cuối câu\n",
    "        if i != len(words)-1 and i != len(words)-2:\n",
    "            # xét từ đồng chí và không có rank\n",
    "            if word in vocative and words[i+1].lower() not in military_rank:\n",
    "                # từ liền trước là xin mời\n",
    "                if words[i-1] == 'xin_mời':\n",
    "                    # nếu từ liền sau là N hoặc Np\n",
    "                    if tags[i+1] in ['N', 'Np', 'V'] or len(words[i+1]) > 5:\n",
    "                        print( 'MĐ: xin mời k có rank '+ words[i+1] + ' TH1' )\n",
    "                        ori_sta = 'xin_mời '+word+' '+ words[i+1]\n",
    "                        sub_sta = '==Đồng chí ' + capital(words[i+1]) + ': '\n",
    "                        final = final.replace(ori_sta, ori_sta + sub_sta)\n",
    "                    # nếu từ liền sau tiếp là N hoặc Np\n",
    "                    elif tags[i+2] in ['N', 'Np', 'V']  or len(words[i+2]) > 5:\n",
    "                        print( 'MĐ: xin mời k có rank '+ words[i+1] + ' TH2' )\n",
    "                        ori_sta = 'xin_mời '+word+' '+ str(words[i+1]) + ' ' + words[i+2]\n",
    "                        sub_sta = '==Đồng chí ' + capital(words[i+1]) + ' ' + words[i+2] +':'\n",
    "                        final = final.replace(ori_sta, ori_sta + sub_sta)\n",
    "            # xét từ rank\n",
    "            if word in vocative and words[i+1].lower() in military_rank:\n",
    "                if words[i-1] == 'xin_mời':\n",
    "                    # nếu từ liền sau là N hoặc Np\n",
    "                    if tags[i+2] in ['N','Np','V'] or len(words[i+2]) > 5:\n",
    "                        print( 'MĐ: xin mời '+ words[i+1] + ' TH1' )\n",
    "                        ori_sta = 'xin_mời '+word+' '+ words[i+1] + ' ' + words[i+2]\n",
    "                        sub_sta = '=='  + str(words[i+1]) + ' ' + capital(words[i+2]) + ': '\n",
    "                        final = final.replace(ori_sta, ori_sta + sub_sta)\n",
    "                    # nếu từ liền sau tiếp là N hoặc Np\n",
    "                    elif tags[i+3] == 'N' or tags[i+3] == 'Np'  or len(words[i+3]) > 5:\n",
    "                        print( 'MĐ: xin mời '+ words[i+1] + ' TH2' )\n",
    "                        ori_sta = 'xin_mời '+word+' '+ words[i+1] +' ' + str(words[i+2]) + ' ' + words[i+3]\n",
    "                        sub_sta = '==' + words[i+1] + ' ' + capital(words[i+2]) + ' ' + capital(words[i+3]) +':'\n",
    "                        final = final.replace(ori_sta, ori_sta + sub_sta)\n",
    "            if word in military_rank:\n",
    "                if words[i-1] == 'xin_mời':\n",
    "                    if tags[i+1] in ['N','Np','V'] or len(words[i+1]) > 5:\n",
    "                        print('MĐ không có từ đồng chí TH1')\n",
    "                        ori_sta = 'xin_mời '+word+' '+ words[i+1]\n",
    "                        sub_sta = '=='+ word + ' ' + capital(words[i+1])+': '\n",
    "                        final = final.replace(ori_sta, ori_sta + sub_sta)\n",
    "                    # nếu từ liền sau tiếp là N hoặc Np\n",
    "                    elif tags[i+2] == 'N' or tags[i+2] == 'Np'  or len(words[i+2]) > 5:\n",
    "                        print('MĐ không có từ đồng chí TH1')\n",
    "                        ori_sta = 'xin_mời '+word+' '+ words[i+1] +' ' + str(words[i+2])\n",
    "                        sub_sta = '==' + capital(words[i+1]) + ' ' + capital(words[i+2]) + ':'\n",
    "                        final = final.replace(ori_sta, ori_sta + sub_sta)\n",
    "\n",
    "    final = final.replace('báo_cáo_hết','==')\n",
    "    final = final.replace('xin_mời','xin mời')\n",
    "    for check in checkpoint_start:\n",
    "        find = re.compile(': '+ check)\n",
    "        for m in find.finditer(final.lower()):\n",
    "            sta_in, end_in = m.start(), m.end()\n",
    "            final = final[0:sta_in] + ': cho_ý_kiến' + final[end_in:]\n",
    "    final = final.replace(': cho_ý_kiến', ':')\n",
    "\n",
    "    paragraph =[para.strip() for para in final.split('==')]\n",
    "    return paragraph\n",
    "\n",
    "# input_1 with file json\n",
    "def process_input(input_1):\n",
    "    text_no_punc = input_1['khong dau']\n",
    "    text_punc = input_1['co dau']\n",
    "    text_done = []\n",
    "    index_replace = []\n",
    "    text_process = '/n '.join(text_no_punc)\n",
    "    #print(text_process)\n",
    "    text_reg = recognize(text_process)\n",
    "    for text in text_reg:\n",
    "        if '/n ' in text:\n",
    "            a = text.split('/n ')\n",
    "            for para in a:\n",
    "                text_done.append(para)\n",
    "        if '/n ' not in text:\n",
    "            text_done.append(text)\n",
    "    for i in range(len(text_done)):\n",
    "        if ':' in text_done[i] and text_done[i] != len(text_done)-1:\n",
    "            x = text_done[i] + ' ' + text_done[i+1]\n",
    "            index_replace.append(i+1)\n",
    "            text_done[i] = x\n",
    "    minus = 0\n",
    "    for i in index_replace:\n",
    "        i -= minus\n",
    "        del text_done[i]\n",
    "        minus += 1\n",
    "    for i in range(len(text_done)-1):\n",
    "        if text_done[i] == '':\n",
    "            del text_done[i]\n",
    "    print(len(text_done), len(text_punc))\n",
    "    if len(text_done) == len(text_punc):\n",
    "        final_text = add_punc(text_done, text_punc)\n",
    "        a = 'Success'\n",
    "    else:\n",
    "        final_text = text_done\n",
    "        a = 'Fail'\n",
    "    return a , final_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xVTMkwTnyL4E",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MĐ: xin mời k có rank Vũ thanhh TH1\n",
      "MĐ: xin mời k có rank Trương Thị Lan TH1\n",
      "5 5\n"
     ]
    }
   ],
   "source": [
    "output,final_text=process_input(Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_IVyy6eSyL4F",
    "outputId": "54eee324-0940-42dd-a630-5aba5b8f5260",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Xin mời đồng chí Vũ thanhh.\\n',\n",
       " 'Đồng chí Vũ Thanhh: \\n Ngày 13/6, Bộ Chỉ huy Bộ đội biên phòng Bà Rịa Vũng Tàu cho biết qua hai ngày 11 và 12/6.\\n kế hoạch tuần tra, bảo vệ chủ quyền vùng biển và phối hợp bảo vệ an ninh an toàn đường ống dẫn khí Nam Côn Sơn\\n lực lượng Biên phòng và công ty đường ống dẫn khí Nam Côn Sơn đã phát hiện 12 Vụ việc với 17 Phương tiện đang Neo Đậu\\n Khai thác đánh bắt thủy hải sản và cận kề hành lang an toàn đường ống dẫn khí dưới biển.\\n Ngày đó tổ tuần tra tàu biên phòng 13.8 01 thuộc Hải đội Biên phòng.\\n Bộ đội biên phòng Bà Rịa Vũng Tàu đã tuần tra dọc hành lang an toàn đường ống dẫn khí Nam Côn Sơn từ km 22 km 90.\\n B75 và ngược lại báo cáo.\\n\\n',\n",
       " 'Xin mời đồng chí Trương Thị Lan\\n',\n",
       " 'Đồng chí Trương Thị Lan: \\n Quá trình tuần tra tổ công tác phát hiện 12 Vụ việc với 17 Phương tiện đang Neo độ khai thác đánh bắt thủy sản trong và cận kề hành lang an toàn đường ống dẫn khí.\\n trong đó đã lập biên bản 4 + 4 phụ việc với táo tàu cá của tỉnh Bà Rịa Vũng Tàu 6 vụ với 8 tàu cá Bình Bình Thuận và 1 mũ 2 tàu cá của tỉnh Bến Tre\\n Nhắc nhở Một tàu cá.\\n Đồng thời, phát tờ rơi in bản đồ tọa độ các tuyến ống dẫn khí dưới đáy biển.\\n tuyên truyền về Nghị định 99, 2020 nghị định\\n Quy định xử phạt vi phạm hành chính trong lĩnh vực dầu khí kinh doanh xăng dầu và khí những hoạt động đó giúp người dân Nâng cao nhận thức đầy đủ về các quy định của nhà nước và những mối nguy hiểm khi hoạt động trong hành lang an toàn đường ống.\\n\\n',\n",
       " 'Xem bài Đồng chí Nguyễn Trung Tín\\n 13/6 của ban nhân dân tỉnh Bình Định cho biết.\\n Có báo cáo gửi bộ nông nghiệp và phát triển nông thôn về kết quả đề.\\n  Tàu cá vi phạm vùng biển nước ngoài khai thác hải sản trái phép năm 2022.\\n  Từ đầu năm đến nay, trên địa bàn tỉnh Bình Định vẫn còn 5 tàu cá với 30 lao động vi phạm vùng biển nước ngoài.\\n Lực lượng chức năng Malaysia bắt giữ.\\n Tàu cá với 10.\\n Lao động bị kiểm soát lấy tiền sản rồi thảo trên biển.\\n  Táo Tàu vi phạm đều ở huyện.\\n Phương liên tục xảy ra tình trạng tàu cá vi phạm hoạt động đánh\\n  Quảng cáo.\\n']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oOMYJUcdyL4F",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "merge_Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('s2t_GCP_Final')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f3627941885a14d666cc947cbc1ebb2879a04e10ef2357a027a72233131ded1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
